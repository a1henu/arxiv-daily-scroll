---
layout: default
title: FlyAwareV2: A Multimodal Cross-Domain UAV Dataset for Urban Scene Understanding
---

# FlyAwareV2: A Multimodal Cross-Domain UAV Dataset for Urban Scene Understanding
**arXiv**：[2510.13243v1](https://arxiv.org/abs/2510.13243) · [PDF](https://arxiv.org/pdf/2510.13243.pdf)  
**作者**：Francesco Barbato, Matteo Caligiuri, Pietro Zanuttigh  

**一句话要点**：提出FlyAwareV2多模态无人机数据集以解决城市场景理解中数据收集困难问题

**关键词**：无人机数据集, 多模态数据, 语义分割, 域适应, 城市场景理解

## 3 点简述
- 核心问题：无人机应用中真实数据收集和标注成本高且困难
- 方法要点：整合真实与合成图像，提供RGB、深度和语义标签多模态数据
- 实验或效果：评估合成到真实域适应，提升模型泛化能力

## 摘要（原文）

> The development of computer vision algorithms for Unmanned Aerial Vehicle
> (UAV) applications in urban environments heavily relies on the availability of
> large-scale datasets with accurate annotations. However, collecting and
> annotating real-world UAV data is extremely challenging and costly. To address
> this limitation, we present FlyAwareV2, a novel multimodal dataset encompassing
> both real and synthetic UAV imagery tailored for urban scene understanding
> tasks. Building upon the recently introduced SynDrone and FlyAware datasets,
> FlyAwareV2 introduces several new key contributions: 1) Multimodal data (RGB,
> depth, semantic labels) across diverse environmental conditions including
> varying weather and daytime; 2) Depth maps for real samples computed via
> state-of-the-art monocular depth estimation; 3) Benchmarks for RGB and
> multimodal semantic segmentation on standard architectures; 4) Studies on
> synthetic-to-real domain adaptation to assess the generalization capabilities
> of models trained on the synthetic data. With its rich set of annotations and
> environmental diversity, FlyAwareV2 provides a valuable resource for research
> on UAV-based 3D urban scene understanding.

