---
layout: default
title: Paper Copilot: Tracking the Evolution of Peer Review in AI Conferences
---

# Paper Copilot: Tracking the Evolution of Peer Review in AI Conferences
**arXiv**：[2510.13201v1](https://arxiv.org/abs/2510.13201) · [PDF](https://arxiv.org/pdf/2510.13201.pdf)  
**作者**：Jing Yang, Qiyao Wei, Jiaxin Pei  

**一句话要点**：提出Paper Copilot系统以解决AI会议同行评审的透明度和可追溯性问题

**关键词**：同行评审系统, 数字档案, 开放数据集, 实证分析, 评审演变, AI会议

## 3 点简述
- AI会议同行评审面临评审员负担重、标准不一致和透明度低等核心问题
- 构建持久数字档案和开放数据集，支持大规模研究评审演变
- 对ICLR多年评审进行实证分析，促进可复现研究和系统改进

## 摘要（原文）

> The rapid growth of AI conferences is straining an already fragile
> peer-review system, leading to heavy reviewer workloads, expertise mismatches,
> inconsistent evaluation standards, superficial or templated reviews, and
> limited accountability under compressed timelines. In response, conference
> organizers have introduced new policies and interventions to preserve review
> standards. Yet these ad-hoc changes often create further concerns and confusion
> about the review process, leaving how papers are ultimately accepted - and how
> practices evolve across years - largely opaque. We present Paper Copilot, a
> system that creates durable digital archives of peer reviews across a wide
> range of computer-science venues, an open dataset that enables researchers to
> study peer review at scale, and a large-scale empirical analysis of ICLR
> reviews spanning multiple years. By releasing both the infrastructure and the
> dataset, Paper Copilot supports reproducible research on the evolution of peer
> review. We hope these resources help the community track changes, diagnose
> failure modes, and inform evidence-based improvements toward a more robust,
> transparent, and reliable peer-review system.

