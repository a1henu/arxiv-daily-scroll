---
layout: default
title: PIA: Deepfake Detection Using Phoneme-Temporal and Identity-Dynamic Analysis
---

# PIA: Deepfake Detection Using Phoneme-Temporal and Identity-Dynamic Analysis
**arXiv**：[2510.14241v1](https://arxiv.org/abs/2510.14241) · [PDF](https://arxiv.org/pdf/2510.14241.pdf)  
**作者**：Soumyya Kanti Datta, Tanvi Ranga, Chengzhe Sun, Siwei Lyu  

**一句话要点**：提出PIA框架，通过多模态分析检测高级生成模型产生的深度伪造视频

**关键词**：深度伪造检测, 多模态分析, 音素-时间分析, 身份动态分析, 音频-视觉融合

## 3 点简述
- 核心问题：传统检测方法难以识别基于GAN、扩散模型等生成的深度伪造视频中的细微时间不一致性
- 方法要点：结合音素序列、唇部几何数据和面部身份嵌入，进行多模态音频-视觉分析
- 实验或效果：集成方法显著提升检测精度，代码已开源

## 摘要（原文）

> The rise of manipulated media has made deepfakes a particularly insidious
> threat, involving various generative manipulations such as lip-sync
> modifications, face-swaps, and avatar-driven facial synthesis. Conventional
> detection methods, which predominantly depend on manually designed
> phoneme-viseme alignment thresholds, fundamental frame-level consistency
> checks, or a unimodal detection strategy, inadequately identify modern-day
> deepfakes generated by advanced generative models such as GANs, diffusion
> models, and neural rendering techniques. These advanced techniques generate
> nearly perfect individual frames yet inadvertently create minor temporal
> discrepancies frequently overlooked by traditional detectors. We present a
> novel multimodal audio-visual framework, Phoneme-Temporal and Identity-Dynamic
> Analysis(PIA), incorporating language, dynamic face motion, and facial
> identification cues to address these limitations. We utilize phoneme sequences,
> lip geometry data, and advanced facial identity embeddings. This integrated
> method significantly improves the detection of subtle deepfake alterations by
> identifying inconsistencies across multiple complementary modalities. Code is
> available at https://github.com/skrantidatta/PIA

