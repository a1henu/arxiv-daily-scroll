---
layout: default
title: VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage
---

# VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage
**arXiv**：[2510.12750v1](https://arxiv.org/abs/2510.12750) · [PDF](https://arxiv.org/pdf/2510.12750.pdf)  
**作者**：A. Alfarano, L. Venturoli, D. Negueruela del Castillo  

**一句话要点**：提出VQArt-Bench基准以评估文化遗产领域的视觉语义理解

**关键词**：视觉问答基准, 文化遗产分析, 多模态大语言模型, 语义理解评估, 多智能体生成

## 3 点简述
- 现有VQA基准缺乏深度语义评估，尤其在艺术分析中依赖表面属性
- 采用多智能体管道生成多样、验证的问题，覆盖符号意义和复杂关系
- 评估14个MLLM显示模型在计数任务和开源与专有模型间存在性能差距

## 摘要（原文）

> Multimodal Large Language Models (MLLMs) have demonstrated significant
> capabilities in joint visual and linguistic tasks. However, existing Visual
> Question Answering (VQA) benchmarks often fail to evaluate deep semantic
> understanding, particularly in complex domains like visual art analysis.
> Confined to simple syntactic structures and surface-level attributes, these
> questions fail to capture the diversity and depth of human visual inquiry. This
> limitation incentivizes models to exploit statistical shortcuts rather than
> engage in visual reasoning. To address this gap, we introduce VQArt-Bench, a
> new, large-scale VQA benchmark for the cultural heritage domain. This benchmark
> is constructed using a novel multi-agent pipeline where specialized agents
> collaborate to generate nuanced, validated, and linguistically diverse
> questions. The resulting benchmark is structured along relevant visual
> understanding dimensions that probe a model's ability to interpret symbolic
> meaning, narratives, and complex visual relationships. Our evaluation of 14
> state-of-the-art MLLMs on this benchmark reveals significant limitations in
> current models, including a surprising weakness in simple counting tasks and a
> clear performance gap between proprietary and open-source models.

