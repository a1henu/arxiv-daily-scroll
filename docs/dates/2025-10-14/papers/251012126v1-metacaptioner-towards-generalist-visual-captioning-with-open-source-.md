---
layout: default
title: MetaCaptioner: Towards Generalist Visual Captioning with Open-source Suites
---

# MetaCaptioner: Towards Generalist Visual Captioning with Open-source Suites
**arXiv**：[2510.12126v1](https://arxiv.org/abs/2510.12126) · [PDF](https://arxiv.org/pdf/2510.12126.pdf)  
**作者**：Zhenxin Lei, Zhangwei Gao, Changyao Tian, Erfei Cui, Guanzhou Chen, Danni Yang, Yuchen Duan, Zhaokai Wang, Wenhao Li, Weiyun Wang, Xiangyu Zhao, Jiayi Ji, Yu Qiao, Wenhai Wang, Gen Luo  

**一句话要点**：提出CapFlow工作流和MetaCaptioner模型，实现低成本高质量通用视觉描述。

**关键词**：通用视觉描述, 多智能体协作, 数据合成, 成本优化, 开源模型

## 3 点简述
- 当前开源视觉描述模型与商业模型性能差距大，限制数据合成等应用。
- 引入CapFlow多智能体协作工作流，利用开源模型降低成本并提升描述质量。
- MetaCaptioner在实验中达到与商业模型相当性能，并在开源社区领先。

## 摘要（原文）

> Generalist visual captioning goes beyond a simple appearance description
> task, but requires integrating a series of visual cues into a caption and
> handling various visual domains. In this task, current open-source models
> present a large performance gap with commercial ones, which limits various
> applications such as data synthesis. To bridge the gap, this paper proposes
> CapFlow, a novel multi-agent collaboration workflow. CapFlow demonstrates for
> the first time that, by capitalizing on open-source models, it is possible to
> achieve caption quality on par with GPT-4.1 in various domains with an 89.5%
> reduction in costs. By leveraging CapFlow as the data synthesizer, we produce
> high-quality visual captions from image and video domains at scale, and obtain
> a generalist visual captioner via fine-tuning, namely MetaCaptioner. Through
> extensive experiments, we show that MetaCaptioner not only achieves comparable
> captioning capabilities with commercial models but also reaches top-tier
> multimodal performance in the open-source community. We hope CapFlow and
> MetaCaptioner can benefit future multimodal research by providing a strong and
> cost-effective visual captioning solution.

